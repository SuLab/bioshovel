articles(
    doc_id              text,
    content             text,
    article_archive     text,
    article_filepath    text,
    corenlp_filepath    text,
    pubtator_filepath   text
).

sentences(
    doc_id         text,
    sentence_index int,
    sentence_text  text,
    tokens         text[],
    lemmas         text[],
    pos_tags       text[],
    ner_tags       text[],
    doc_offsets    int[],
    dep_types      text[],
    dep_tokens     int[]
).

biothing_token(
    type                text,
    token_id            int,
    sentence_index      int,
    doc_id              text,
    mesh_id             text,
    token_start_char    int,
    token_end_char      int,
    pubtator_start_char int,
    pubtator_end_char   int 
).

corenlp_token(
    type                text,
    sentence_index      int,
    doc_id              text,
    token_text          text,
    token_start_char    int
).

corenlp_token(unnest(ner_tags), sentence_index, doc_id, unnest(token_text), unnest(doc_offsets)) :-
    sentences(doc_id, sentence_index, _, token_text, _, _, ner_tags, doc_offsets, _, _).

// working:
// biothing_token(unnest(ner_tags), 4, sentence_index, doc_id, "mesh_id", unnest(doc_offsets), 0, 1) :-
//     sentences(doc_id, sentence_index, _, _, _, _, ner_tags, doc_offsets, _, _).
